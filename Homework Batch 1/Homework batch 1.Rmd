---
title: "Homework batch 1"
author: "Waheeb Algabri, William Berritt ,Kossi Akplaka "
output:
  html_document:
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```


```{r}
library(fpp3)
library(readxl)
library(fpp2)
library(ggplot2)
```

### Introduction

This assignment is to be submitted via email by the designated group representative and follows the Hyndman Version for the problems assigned in batch #1. The first batch consists of 12 problems, drawn from both KJ and HA sources. The problems to be addressed are as follows:

The tasks outlined in these problems will require a thorough understanding of the materials covered in the specified chapters, ensuring a comprehensive grasp of the subject matter.



### Exercise 2.3

3. Download some monthly Australian retail data from OTexts.org/fpp2/extrafiles/retail.xlsx. These represent retail sales in various categories for different Australian states, and are stored in a MS-Excel file.


a. Read the data into R
```{r include=FALSE}

 # The second argument (skip = 1) is required because the Excel sheet has two header rows
retaildata <- readxl::read_excel("Homework Batch 1/retail.xlsx", skip = 1)

```

b. Select one of the time series as follows (but replace the column name with your own chosen column):

```{r}
myts <- ts(retaildata[, "A3349337W"], frequency = 12, start = c(1982, 4))
```

c. Explore your chosen retail time series using the following functions:

autoplot(), ggseasonplot(), ggsubseriesplot(), gglagplot(), ggAcf()

Can you spot any seasonality, cyclicity and trend? What do you learn about the series?

```{r}
autoplot(myts) + ggtitle("A3349337W") +
  xlab("Year") + ylab("Sales")
```

The autoplot shows a strong seasonality to the data, as well as an upward trend. Though there is a brief dip from 1990-2000, there is no evidence that this is part of a cycle yet.

```{r}
ggseasonplot(myts, year.labels = TRUE, year.labels.left = TRUE) +
  ylab("Sales") + ggtitle("Seasonal Plot of A3349337W")
```

The seasonal plot emphasizes the seasonality of the data. Sales start to rise in the fall before spiking sharply between November and December, then falling off after January, obviously coinciding with holiday shopping and sales for Christmas.

```{r}
ggsubseriesplot(myts) + ylab("Sales") +
  ggtitle("Seasonal Subseries Plot of A3349337W")
```

Again, the subseries highlights the seasonality of the data, but paints it clearer than the seasonal plot. Though sales rise from September, the floor actually remains the same. The only real difference is in December, which not only has a higher ceiling, but a higher floor as well.

```{r}
gglagplot(myts)
```

The data is not very readable in this lag series. We can see some negative relationships and some positive relationships, but the amount of graphs, and the fact that this is monthly, make it difficult to discern much.

```{r}
ggAcf(myts)
```

The decrease in lags highlights the trend, while the scalloped shape shows the seasonality of the sales data.


***

### Exercise 7.1

1. Consider the pigs series - the number of pigs slaughtered in Victoria each month.
 
 
* a) Use the ses() function in R to find the optimal values of  alpha and l0 , and generate forecasts for the next four months.

```{r warning=FALSE, message=FALSE}

#summary(pigs)

summary(ses(pigs,h=4))
```

From the output, we observe the alpha to be 0.2971 and sigma to be 10308.58

* b) Compute a 95% prediction interval for the first forecast using yÂ±1.96 s where s is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r warning=FALSE, message=FALSE}

s<-sd((ses(pigs, h=4))$residuals)
print(paste0("lower Confidence Interval: ", ses(pigs,h=4)$mean[1]-1.96*s))
print(paste0("Upper Confidence Interval: ", ses(pigs,h=4)$mean[1]+1.96*s))


```

Our confidence intervals are slightly different than the ones produced by r's output. They seem to be more narrow.

```{r}
ses_pigs <- ses(pigs, h = 4)

# plot the data, fitted values and forecasts.
autoplot(ses_pigs) +
  autolayer(ses_pigs$fitted)
```

### Exercise 7.2

2. Write your own function to implement simple exponential smoothing. The function should take arguments y (the time series), alpha (the smoothing parameter alpha) and level (the initial level l0). It should return the forecast of the next observation in the series. Does it give the same forecast as ses?

```{r}
SES <- function(y, alpha, l0){
  y_hat <- l0
  for(index in 1:length(y)){
    y_hat <- alpha * y[index] + (1 - alpha) * y_hat
  }
  return(y_hat)
}

# Extract the optimal alpha and l0 from the ses model
alpha <- ses_pigs$model$par[1]
l0 <- ses_pigs$model$par[2]

# Use the custom SES function to forecast the next observation
forecast_SES <- SES(pigs, alpha, l0)
print(paste("Forecast of next observation by SES function: ", forecast_SES))

# Compare with the forecast from the ses function
print(paste("Forecast of next observation by ses function: ", ses_pigs$mean[1]))

```


Found that SES function worked just like ses function.


###  Exercise 7.3
Modify your function from the previous exercise to return the sum of squared errors rather than the forecast of the next observation. Then use the optim() function to find the optimal values of  
alpha and lo. Do you get the same values as the ses() function?


```{r}
SSE_SES <- function(params, y){
  alpha <- params[1]
  l0 <- params[2]
  y_hat <- l0
  sse <- 0
  for(index in 1:length(y)){
    sse <- sse + (y[index] - y_hat)^2
    y_hat <- alpha * y[index] + (1 - alpha) * y_hat
  }
  return(sse)
}

# Use optim() to find the optimal alpha and l0
initial_params <- c(0.5, pigs[1])  # Initial guess for alpha and l0
opt_result <- optim(initial_params, SSE_SES, y = pigs, method = "L-BFGS-B", lower = c(0, 0), upper = c(1, Inf))

# Extract the optimal parameters
optimal_alpha <- opt_result$par[1]
optimal_l0 <- opt_result$par[2]

print(paste("Optimal alpha: ", optimal_alpha))
print(paste("Optimal l0: ", optimal_l0))

```


The optimal values obtained using the custom optimization function are very close but not exactly the same as the values obtained by the ses() function.

***

###  Exercise 8.6



###  Exercise 8.8

Consider austa, the total international visitors to Australia (in millions) for the period 1980-2015.

Step 1: Use auto.arima() to Find an Appropriate ARIMA Model

```{r}
library(forecast)

# Load data
data("austa")

# 1. Find an appropriate ARIMA model using auto.arima()
auto_arima_model <- auto.arima(austa)
auto_arima_model
```

Step 2: Check That the Residuals Look Like White Noise

```{r}
# 2. Check residuals for white noise
checkresiduals(auto_arima_model)

```

Step 3: Plot Forecasts for the Next 10 Periods and Plot forecasts from ARIMA


```{r}

# 3. Plot forecasts for the next 10 periods
autoplot(forecast(auto_arima_model, h = 10))

# 4. ARIMA(0,1,1) model with no drift
arima_011_no_drift <- Arima(austa, order = c(0,1,1), include.drift = FALSE)
autoplot(forecast(arima_011_no_drift, h = 10))

# 5. Remove MA term from ARIMA(0,1,1) model and plot forecasts again
arima_010_no_drift <- Arima(austa, order = c(0,1,0), include.drift = FALSE)
autoplot(forecast(arima_010_no_drift, h = 10))

# 6. ARIMA(2,1,3) model with drift and remove constant
arima_213_with_drift <- Arima(austa, order = c(2,1,3), include.drift = TRUE, include.mean = FALSE)
autoplot(forecast(arima_213_with_drift, h = 10))

# 7. ARIMA(0,0,1) model with constant and remove MA term
arima_001_with_constant <- Arima(austa, order = c(0,0,1), include.drift = FALSE, include.mean = TRUE)
autoplot(forecast(arima_001_with_constant, h = 10))

# 8. ARIMA(0,2,1) model with no constant
arima_021_no_constant <- Arima(austa, order = c(0,2,1), include.drift = FALSE, include.mean = FALSE)
autoplot(forecast(arima_021_no_constant, h = 10))

```


The ARIMA(0,1,1) model with drift seems to provide a reasonable fit to the austa series, with non-significant autocorrelation in the residuals and relatively low information criteria values.


